{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "TPgogXk6c_NA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "gfUD4gwpdGtD"
   },
   "outputs": [],
   "source": [
    "f=open('train_data1.npz','rb')\n",
    "npzfile = np.load(f)\n",
    "images=npzfile['arr_0']\n",
    "labels=npzfile['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3032,
     "status": "ok",
     "timestamp": 1533174752676,
     "user": {
      "displayName": "Hari Krishnan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116369642993621286939"
     },
     "user_tz": -330
    },
    "id": "F4a0Nveh9vTB",
    "outputId": "fc538b0a-daf9-4409-a922-f2dc19d45be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8382, 64, 64, 1)\n",
      "(1840, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing set\n",
    "split_point = int(len(images)*0.82)\n",
    "test_img=list(images[:-split_point])\n",
    "test_labels=list(labels[:-split_point])\n",
    "train_img=list(images[:split_point])\n",
    "train_labels=list(labels[:split_point])\n",
    "train_img=np.array(train_img)\n",
    "test_img=np.array(test_img)\n",
    "train_labels=np.array(train_labels)\n",
    "test_labels=np.array(test_labels)\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Dh7Gq30B_1e0"
   },
   "outputs": [],
   "source": [
    "input_shape=images.shape[1:]\n",
    "num_classes=120\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, input_shape=input_shape))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(120, activation='softmax'))\n",
    "model.compile(loss=losses.categorical_crossentropy,\n",
    "              optimizer=optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3454
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 576683,
     "status": "ok",
     "timestamp": 1533176139034,
     "user": {
      "displayName": "Hari Krishnan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116369642993621286939"
     },
     "user_tz": -330
    },
    "id": "iKneLovm4Ac1",
    "outputId": "9e4317ec-2588-4419-b8ce-09e7f109703d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8382/8382 [==============================] - 10s 1ms/step - loss: 4.8331 - acc: 0.0119\n",
      "Epoch 2/100\n",
      "8382/8382 [==============================] - 8s 980us/step - loss: 4.7819 - acc: 0.0165\n",
      "Epoch 3/100\n",
      "8382/8382 [==============================] - 8s 984us/step - loss: 4.7498 - acc: 0.0166\n",
      "Epoch 4/100\n",
      "3488/8382 [===========>..................] - ETA: 4s - loss: 4.7342 - acc: 0.02268382/8382 [==============================] - 8s 980us/step - loss: 4.7295 - acc: 0.0199\n",
      "Epoch 5/100\n",
      "8382/8382 [==============================] - 8s 988us/step - loss: 4.6987 - acc: 0.0214\n",
      "Epoch 6/100\n",
      "8382/8382 [==============================] - 8s 1ms/step - loss: 4.6533 - acc: 0.0268\n",
      "Epoch 7/100\n",
      "4896/8382 [================>.............] - ETA: 3s - loss: 4.6187 - acc: 0.0288382/8382 [==============================] - 8s 1ms/step - loss: 4.6186 - acc: 0.0258\n",
      "Epoch 8/100\n",
      "8382/8382 [==============================] - 8s 985us/step - loss: 4.5653 - acc: 0.0295\n",
      "Epoch 9/100\n",
      "8382/8382 [==============================] - 8s 995us/step - loss: 4.5272 - acc: 0.0321\n",
      "Epoch 10/100\n",
      "5504/8382 [==================>...........] - ETA: 2s - loss: 4.5002 - acc: 0.03238382/8382 [==============================] - 8s 995us/step - loss: 4.4967 - acc: 0.0342\n",
      "Epoch 11/100\n",
      "8382/8382 [==============================] - 9s 1ms/step - loss: 4.4708 - acc: 0.0375\n",
      "Epoch 12/100\n",
      "8382/8382 [==============================] - 8s 996us/step - loss: 4.4422 - acc: 0.0407\n",
      "Epoch 13/100\n",
      "5248/8382 [=================>............] - ETA: 3s - loss: 4.4264 - acc: 0.04008382/8382 [==============================] - 8s 1ms/step - loss: 4.4239 - acc: 0.0437\n",
      "Epoch 14/100\n",
      "8382/8382 [==============================] - 7s 781us/step - loss: 4.4023 - acc: 0.0452\n",
      "Epoch 15/100\n",
      "8382/8382 [==============================] - 5s 635us/step - loss: 4.3842 - acc: 0.0438\n",
      "Epoch 16/100\n",
      "8382/8382 [==============================] - 5s 579us/step - loss: 4.3699 - acc: 0.0466\n",
      "Epoch 17/100\n",
      "2720/8382 [========>.....................] - ETA: 3s - loss: 4.3253 - acc: 0.05598382/8382 [==============================] - 5s 578us/step - loss: 4.3518 - acc: 0.0463\n",
      "Epoch 18/100\n",
      "8382/8382 [==============================] - 5s 573us/step - loss: 4.3401 - acc: 0.0501\n",
      "Epoch 19/100\n",
      "8382/8382 [==============================] - 5s 567us/step - loss: 4.3239 - acc: 0.0529\n",
      "Epoch 20/100\n",
      "8382/8382 [==============================] - 5s 576us/step - loss: 4.3204 - acc: 0.0502\n",
      "Epoch 21/100\n",
      "3744/8382 [============>.................] - ETA: 2s - loss: 4.3050 - acc: 0.05028382/8382 [==============================] - 5s 579us/step - loss: 4.3002 - acc: 0.0521\n",
      "Epoch 22/100\n",
      "8382/8382 [==============================] - 5s 576us/step - loss: 4.2878 - acc: 0.0538\n",
      "Epoch 23/100\n",
      "8382/8382 [==============================] - 5s 578us/step - loss: 4.2757 - acc: 0.0545\n",
      "Epoch 24/100\n",
      "8382/8382 [==============================] - 5s 578us/step - loss: 4.2584 - acc: 0.0583\n",
      "Epoch 25/100\n",
      "3872/8382 [============>.................] - ETA: 2s - loss: 4.2458 - acc: 0.06028382/8382 [==============================] - 5s 576us/step - loss: 4.2349 - acc: 0.0647\n",
      "Epoch 26/100\n",
      "8382/8382 [==============================] - 5s 580us/step - loss: 4.2395 - acc: 0.0649\n",
      "Epoch 27/100\n",
      "8382/8382 [==============================] - 5s 585us/step - loss: 4.2130 - acc: 0.0645\n",
      "Epoch 28/100\n",
      "8382/8382 [==============================] - 5s 584us/step - loss: 4.2044 - acc: 0.0641\n",
      "Epoch 29/100\n",
      "3840/8382 [============>.................] - ETA: 2s - loss: 4.1686 - acc: 0.06388382/8382 [==============================] - 5s 580us/step - loss: 4.1893 - acc: 0.0647\n",
      "Epoch 30/100\n",
      "8382/8382 [==============================] - 5s 578us/step - loss: 4.1817 - acc: 0.0655\n",
      "Epoch 31/100\n",
      "8382/8382 [==============================] - 5s 574us/step - loss: 4.1805 - acc: 0.0680\n",
      "Epoch 32/100\n",
      "8382/8382 [==============================] - 5s 573us/step - loss: 4.1576 - acc: 0.0678\n",
      "Epoch 33/100\n",
      "3776/8382 [============>.................] - ETA: 2s - loss: 4.1379 - acc: 0.06838382/8382 [==============================] - 5s 578us/step - loss: 4.1566 - acc: 0.0685\n",
      "Epoch 34/100\n",
      "8382/8382 [==============================] - 5s 577us/step - loss: 4.1330 - acc: 0.0737\n",
      "Epoch 35/100\n",
      "8382/8382 [==============================] - 5s 568us/step - loss: 4.1187 - acc: 0.0781\n",
      "Epoch 36/100\n",
      "8382/8382 [==============================] - 5s 580us/step - loss: 4.1127 - acc: 0.0731\n",
      "Epoch 37/100\n",
      "3968/8382 [=============>................] - ETA: 2s - loss: 4.0974 - acc: 0.07968382/8382 [==============================] - 5s 572us/step - loss: 4.1009 - acc: 0.0770\n",
      "Epoch 38/100\n",
      "8382/8382 [==============================] - 5s 572us/step - loss: 4.0986 - acc: 0.0775\n",
      "Epoch 39/100\n",
      "8382/8382 [==============================] - 5s 587us/step - loss: 4.0874 - acc: 0.0828\n",
      "Epoch 40/100\n",
      "8382/8382 [==============================] - 5s 595us/step - loss: 4.0737 - acc: 0.0832\n",
      "Epoch 41/100\n",
      "3968/8382 [=============>................] - ETA: 2s - loss: 4.0760 - acc: 0.07918382/8382 [==============================] - 5s 588us/step - loss: 4.0674 - acc: 0.0791\n",
      "Epoch 42/100\n",
      "8382/8382 [==============================] - 5s 578us/step - loss: 4.0409 - acc: 0.0878\n",
      "Epoch 43/100\n",
      "8382/8382 [==============================] - 5s 574us/step - loss: 4.0382 - acc: 0.0896\n",
      "Epoch 44/100\n",
      "8382/8382 [==============================] - 5s 568us/step - loss: 4.0346 - acc: 0.0841\n",
      "Epoch 45/100\n",
      "3872/8382 [============>.................] - ETA: 2s - loss: 4.0011 - acc: 0.08068382/8382 [==============================] - 5s 576us/step - loss: 4.0149 - acc: 0.0853\n",
      "Epoch 46/100\n",
      "8382/8382 [==============================] - 5s 578us/step - loss: 4.0162 - acc: 0.0878\n",
      "Epoch 47/100\n",
      "8382/8382 [==============================] - 5s 576us/step - loss: 4.0006 - acc: 0.0939\n",
      "Epoch 48/100\n",
      "8382/8382 [==============================] - 5s 573us/step - loss: 3.9869 - acc: 0.0970\n",
      "Epoch 49/100\n",
      "3872/8382 [============>.................] - ETA: 2s - loss: 3.9433 - acc: 0.09278382/8382 [==============================] - 5s 575us/step - loss: 3.9766 - acc: 0.0902\n",
      "Epoch 50/100\n",
      "8382/8382 [==============================] - 5s 579us/step - loss: 3.9594 - acc: 0.0976\n",
      "Epoch 51/100\n",
      "8382/8382 [==============================] - 5s 572us/step - loss: 3.9534 - acc: 0.0963\n",
      "Epoch 52/100\n",
      "8382/8382 [==============================] - 5s 578us/step - loss: 3.9337 - acc: 0.1018\n",
      "Epoch 53/100\n",
      "3968/8382 [=============>................] - ETA: 2s - loss: 3.9135 - acc: 0.10268382/8382 [==============================] - 5s 586us/step - loss: 3.9269 - acc: 0.1005\n",
      "Epoch 54/100\n",
      "8382/8382 [==============================] - 5s 582us/step - loss: 3.9189 - acc: 0.1030\n",
      "Epoch 55/100\n",
      "8382/8382 [==============================] - 5s 580us/step - loss: 3.9120 - acc: 0.1055\n",
      "Epoch 56/100\n",
      "8382/8382 [==============================] - 5s 578us/step - loss: 3.9013 - acc: 0.1069\n",
      "Epoch 57/100\n",
      "3840/8382 [============>.................] - ETA: 2s - loss: 3.8963 - acc: 0.10708382/8382 [==============================] - 5s 582us/step - loss: 3.8910 - acc: 0.1094\n",
      "Epoch 58/100\n",
      "8382/8382 [==============================] - 5s 588us/step - loss: 3.8786 - acc: 0.1045\n",
      "Epoch 59/100\n",
      "8382/8382 [==============================] - 5s 587us/step - loss: 3.8704 - acc: 0.1106\n",
      "Epoch 60/100\n",
      "8382/8382 [==============================] - 5s 588us/step - loss: 3.8709 - acc: 0.1073\n",
      "Epoch 61/100\n",
      "3840/8382 [============>.................] - ETA: 2s - loss: 3.8129 - acc: 0.11938382/8382 [==============================] - 5s 587us/step - loss: 3.8358 - acc: 0.1158\n",
      "Epoch 62/100\n",
      "8382/8382 [==============================] - 5s 585us/step - loss: 3.8124 - acc: 0.1163\n",
      "Epoch 63/100\n",
      "8382/8382 [==============================] - 5s 585us/step - loss: 3.8284 - acc: 0.1139\n",
      "Epoch 64/100\n",
      "8382/8382 [==============================] - 5s 584us/step - loss: 3.8199 - acc: 0.1152\n",
      "Epoch 65/100\n",
      "3840/8382 [============>.................] - ETA: 2s - loss: 3.7989 - acc: 0.11438382/8382 [==============================] - 5s 581us/step - loss: 3.8045 - acc: 0.1145\n",
      "Epoch 66/100\n",
      "8382/8382 [==============================] - 5s 586us/step - loss: 3.8062 - acc: 0.1193\n",
      "Epoch 67/100\n",
      "8382/8382 [==============================] - 5s 581us/step - loss: 3.7700 - acc: 0.1240\n",
      "Epoch 68/100\n",
      "8382/8382 [==============================] - 5s 583us/step - loss: 3.7764 - acc: 0.1174\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3872/8382 [============>.................] - ETA: 2s - loss: 3.7305 - acc: 0.12608382/8382 [==============================] - 5s 585us/step - loss: 3.7582 - acc: 0.1216\n",
      "Epoch 70/100\n",
      "8382/8382 [==============================] - 5s 579us/step - loss: 3.7543 - acc: 0.1244\n",
      "Epoch 71/100\n",
      "8382/8382 [==============================] - 5s 578us/step - loss: 3.7473 - acc: 0.1269\n",
      "Epoch 72/100\n",
      "8382/8382 [==============================] - 5s 575us/step - loss: 3.7440 - acc: 0.1283\n",
      "Epoch 73/100\n",
      "3968/8382 [=============>................] - ETA: 2s - loss: 3.7126 - acc: 0.12658382/8382 [==============================] - 5s 583us/step - loss: 3.7253 - acc: 0.1254\n",
      "Epoch 74/100\n",
      "8382/8382 [==============================] - 5s 584us/step - loss: 3.7204 - acc: 0.1300\n",
      "Epoch 75/100\n",
      "8382/8382 [==============================] - 5s 584us/step - loss: 3.7060 - acc: 0.1303\n",
      "Epoch 76/100\n",
      "8382/8382 [==============================] - 5s 577us/step - loss: 3.6879 - acc: 0.1347\n",
      "Epoch 77/100\n",
      "3776/8382 [============>.................] - ETA: 2s - loss: 3.6896 - acc: 0.12478382/8382 [==============================] - 5s 576us/step - loss: 3.6869 - acc: 0.1327\n",
      "Epoch 78/100\n",
      "8382/8382 [==============================] - 5s 575us/step - loss: 3.6731 - acc: 0.1359\n",
      "Epoch 79/100\n",
      "8382/8382 [==============================] - 5s 580us/step - loss: 3.6589 - acc: 0.1380\n",
      "Epoch 80/100\n",
      "8382/8382 [==============================] - 5s 572us/step - loss: 3.6610 - acc: 0.1348\n",
      "Epoch 81/100\n",
      "3968/8382 [=============>................] - ETA: 2s - loss: 3.6233 - acc: 0.14048382/8382 [==============================] - 5s 566us/step - loss: 3.6308 - acc: 0.1446\n",
      "Epoch 82/100\n",
      "8382/8382 [==============================] - 5s 574us/step - loss: 3.6369 - acc: 0.1434\n",
      "Epoch 83/100\n",
      "8382/8382 [==============================] - 5s 574us/step - loss: 3.6207 - acc: 0.1457\n",
      "Epoch 84/100\n",
      "8382/8382 [==============================] - 5s 577us/step - loss: 3.6143 - acc: 0.1451\n",
      "Epoch 85/100\n",
      "3840/8382 [============>.................] - ETA: 2s - loss: 3.5850 - acc: 0.14588382/8382 [==============================] - 5s 583us/step - loss: 3.6121 - acc: 0.1446\n",
      "Epoch 86/100\n",
      "8382/8382 [==============================] - 5s 625us/step - loss: 3.5884 - acc: 0.1428\n",
      "Epoch 87/100\n",
      "8382/8382 [==============================] - 5s 625us/step - loss: 3.5848 - acc: 0.1553\n",
      "Epoch 88/100\n",
      "8224/8382 [============================>.] - ETA: 0s - loss: 3.5728 - acc: 0.15208382/8382 [==============================] - 9s 1ms/step - loss: 3.5721 - acc: 0.1515\n",
      "Epoch 89/100\n",
      "8382/8382 [==============================] - 7s 887us/step - loss: 3.5564 - acc: 0.1592\n",
      "Epoch 90/100\n",
      "8382/8382 [==============================] - 7s 885us/step - loss: 3.5365 - acc: 0.1524\n",
      "Epoch 91/100\n",
      "7072/8382 [========================>.....] - ETA: 1s - loss: 3.5518 - acc: 0.15198382/8382 [==============================] - 8s 902us/step - loss: 3.5593 - acc: 0.1531\n",
      "Epoch 92/100\n",
      "8382/8382 [==============================] - 8s 916us/step - loss: 3.5451 - acc: 0.1558\n",
      "Epoch 93/100\n",
      "8382/8382 [==============================] - 8s 897us/step - loss: 3.5263 - acc: 0.1521\n",
      "Epoch 94/100\n",
      "6304/8382 [=====================>........] - ETA: 1s - loss: 3.5079 - acc: 0.16428382/8382 [==============================] - 8s 955us/step - loss: 3.5126 - acc: 0.1649\n",
      "Epoch 95/100\n",
      "8382/8382 [==============================] - 9s 1ms/step - loss: 3.4968 - acc: 0.1651\n",
      "Epoch 96/100\n",
      "8382/8382 [==============================] - 6s 733us/step - loss: 3.5020 - acc: 0.1618\n",
      "Epoch 97/100\n",
      "8382/8382 [==============================] - 5s 587us/step - loss: 3.4842 - acc: 0.1670\n",
      "Epoch 98/100\n",
      "1344/8382 [===>..........................] - ETA: 4s - loss: 3.4289 - acc: 0.17868382/8382 [==============================] - 6s 763us/step - loss: 3.4628 - acc: 0.1650\n",
      "Epoch 99/100\n",
      "8382/8382 [==============================] - 7s 817us/step - loss: 3.4463 - acc: 0.1707\n",
      "Epoch 100/100\n",
      "8382/8382 [==============================] - 6s 670us/step - loss: 3.4369 - acc: 0.1736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff23e097358>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_img,train_labels,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13058,
     "status": "ok",
     "timestamp": 1533176152395,
     "user": {
      "displayName": "Hari Krishnan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "116369642993621286939"
     },
     "user_tz": -330
    },
    "id": "SOCAJF-n5Bks",
    "outputId": "0516bb2f-8a46-47fd-baef-80b696392555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1840/1840 [==============================] - 1s 379us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.983675054881884, 0.2875]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_img,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "p-b6iQ5-Xbzi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Keras Dog Breed.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
